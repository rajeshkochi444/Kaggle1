{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63694e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0024124d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 1568)\n",
      "(10000, 1568)\n"
     ]
    }
   ],
   "source": [
    "train_X = pd.read_csv('train.csv')\n",
    "test_X = pd.read_csv('test.csv' )\n",
    "train_X.drop(train_X.columns[train_X.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\n",
    "test_X.drop(test_X.columns[test_X.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\n",
    "print(train_X.shape)\n",
    "print(test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20ee2431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "40000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# Shuffle your dataset \n",
    "shuffle_train_X = train_X.sample(frac=1, random_state=999)\n",
    "print(len(shuffle_train_X))\n",
    "\n",
    "# Define a size for your train set \n",
    "train_size = int(0.8 * len(train_X))\n",
    "\n",
    "# Split your dataset \n",
    "train_set = shuffle_train_X[:train_size]\n",
    "val_set = shuffle_train_X[train_size:]\n",
    "print(len(train_set))\n",
    "#print(train_set)\n",
    "print(len(val_set))\n",
    "#print(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e883235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 1568)\n",
      "(10000, 1568)\n",
      "(10000, 1568)\n"
     ]
    }
   ],
   "source": [
    "X_train = train_set.to_numpy()\n",
    "X_val = val_set.to_numpy()\n",
    "X_test = test_X.to_numpy()\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36a3a2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n",
      "(40000,)\n"
     ]
    }
   ],
   "source": [
    "val_idx = val_set.index.to_list()\n",
    "train_idx = train_set.index.to_list()\n",
    "#print(val_idx)\n",
    "#print(train_idx)\n",
    "train_result = pd.read_csv('train_result.csv')\n",
    "new_train_y = train_result.iloc[train_idx]\n",
    "new_val_y = train_result.iloc[val_idx]\n",
    "\n",
    "val_y_class = new_val_y['Class']\n",
    "val_y = val_y_class.to_numpy()\n",
    "\n",
    "train_y_class = new_train_y['Class']\n",
    "train_y = train_y_class.to_numpy()\n",
    "print(val_y.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fddcd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ea8d199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(y, c):\n",
    "    \n",
    "    # y--> label/ground truth.\n",
    "    # c--> Number of classes.\n",
    "    \n",
    "    # A zero matrix of size (m, c)\n",
    "    y_hot = np.zeros((len(y), c))\n",
    "    \n",
    "    # Putting 1 for column where the label is,\n",
    "    # Using multidimensional indexing.\n",
    "    y_hot[np.arange(len(y)), y] = 1\n",
    "    \n",
    "    return y_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1765eae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    \n",
    "    # z--> linear part.\n",
    "    \n",
    "    # subtracting the max of z for numerical stability.\n",
    "    exp = np.exp(z - np.max(z))\n",
    "    \n",
    "    # Calculating softmax for all examples.\n",
    "    for i in range(len(z)):\n",
    "        exp[i] /= np.sum(exp[i])\n",
    "        \n",
    "    return exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb69f7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, w, b):\n",
    "    \n",
    "    # X --> Input.\n",
    "    # w --> weights.\n",
    "    # b --> bias.\n",
    "    \n",
    "    # Predicting\n",
    "    z = X@w + b\n",
    "    y_hat = softmax(z)\n",
    "    \n",
    "    # Returning the class with highest probability.\n",
    "    return np.argmax(y_hat, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7947cf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_accuracy(y, y_hat):\n",
    "    return np.sum(y==y_hat)/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cd11d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict_accuracy(X, y, w, b):\n",
    "        \n",
    "    preds = predict(X, w, b)\n",
    "    model_accuracy = prediction_accuracy(y, preds)\n",
    "\n",
    "    n_classes = len(np.unique(y))\n",
    "    \n",
    "    confusion_matrix = np.zeros((n_classes,n_classes))\n",
    "    for (true, pred) in zip(y, preds):\n",
    "        confusion_matrix[int(true-1), int(pred-1)] += 1\n",
    "\n",
    "    #misclassification_error(confusion_matrix):\n",
    "    sum_preds = np.sum(confusion_matrix)\n",
    "    sum_correct = np.sum(np.diag(confusion_matrix))\n",
    "    misclassification_error = 1.0 - (float(sum_correct) / float(sum_preds))\n",
    "    \n",
    "    #print('\\n')\n",
    "    #print(\"Accuracy:\",model_accuracy)\n",
    "    #print('confusion_matrix:')\n",
    "    #print(confusion_matrix, '\\n')\n",
    "    #print(\"sum_preds               :\", int(sum_preds)) \n",
    "    #print(\"sum_correct_predictions :\", int(sum_correct)) \n",
    "    #print(\"sum_wrong_predictions   :\", int(sum_preds - sum_correct))\n",
    "    #print(\"misclassification_error :\", misclassification_error)\n",
    "    #plt.plot(losses)\n",
    "    \n",
    "    return model_accuracy, confusion_matrix, sum_preds, sum_correct, misclassification_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6dc872e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_reg_lamb(X, y, lr, epochs, lamb):\n",
    "    \n",
    "    # X --> Input.\n",
    "    # y --> true/target value.\n",
    "    # lr --> Learning rate.\n",
    "    # c --> Number of classes.\n",
    "    # epochs --> Number of iterations.\n",
    "    \n",
    "        \n",
    "    # m-> number of training examples\n",
    "    # n-> number of features \n",
    "    m, n = X.shape\n",
    "    #print(X.shape)\n",
    "    \n",
    "    c = len(np.unique(y)) # number of classes based on unique y values usually train_y values\n",
    "\n",
    "    \n",
    "    # Initializing weights and bias randomly.\n",
    "    np.random.seed(999)\n",
    "    w = np.random.random((n, c))\n",
    "    b = np.random.random(c)\n",
    "    #print(w.shape)\n",
    "    #print(b.shape)\n",
    "    \n",
    "    # Empty list to store losses.\n",
    "    losses = []\n",
    "    \n",
    "    # Training loop.\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # Calculating hypothesis/prediction.\n",
    "        z = X@w + b\n",
    "        #print(z.shape)\n",
    "       \n",
    "        y_hat = softmax(z)\n",
    "        #print(y_hat.shape)\n",
    "       \n",
    "        \n",
    "        # One-hot encoding y.\n",
    "        y_hot = one_hot(y, c)\n",
    "        #print(y_hot.shape)\n",
    "        # Calculating the gradient of loss w.r.t w and b.\n",
    "        w_grad = (1/m)* ( np.dot(X.T, (y_hat - y_hot)) + lamb*w)\n",
    "        #w_grad1 = (1/m)* ( np.dot(X.T, (y_hat - y_hot))) + (lamb/m)*w\n",
    "        #print(\"w_grad - w_grad1\")\n",
    "        #print(np.round(w_grad - w_grad1, 12))\n",
    "       \n",
    "        b_grad = (1/m)*np.sum(y_hat - y_hot)\n",
    "\n",
    "        # Updating the parameters.\n",
    "        w = w - lr*w_grad\n",
    "        b = b - lr*b_grad\n",
    "\n",
    "        # Calculating loss and appending it in the list.\n",
    "        #loss = -np.mean(np.log(y_hat[np.arange(len(y)), y]))\n",
    "        #loss_old=-np.sum(y_hot*np.log(y_hat))/float(y_hat.shape[0])\n",
    "        \n",
    "        cross_entropy = - np.sum(np.log(y_hat) * (y_hot), axis=1)\n",
    "        loss = np.mean(cross_entropy)\n",
    "        \n",
    "        reg_cost = (lamb/(2*m))*np.sum(w*w)\n",
    "        total_costJ = loss + reg_cost \n",
    "        #print('loss, reg_cost, total_costJ')\n",
    "        #print(loss, reg_cost, total_costJ)\n",
    "        \n",
    "        losses.append(total_costJ)\n",
    "        \n",
    "        # Printing out the total cost after regularization at every 100th iteration.\n",
    "        #if epoch%100==0:\n",
    "            #print(f'Epoch {epoch} ==> Total CostJ = {total_costJ}')\n",
    "\n",
    "    return w, b, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b0734d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b065120f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lr:     0.0010 Lambda:     0.0010 Epochs: 2000 Train Accuracy:     0.0794 Validation Accuracy:     0.0785\n",
      "Lr:     0.0010 Lambda:     0.0100 Epochs: 2000 Train Accuracy:     0.0794 Validation Accuracy:     0.0785\n",
      "Lr:     0.0010 Lambda:     0.1000 Epochs: 2000 Train Accuracy:     0.0794 Validation Accuracy:     0.0785\n",
      "Lr:     0.0010 Lambda:     1.0000 Epochs: 2000 Train Accuracy:     0.0794 Validation Accuracy:     0.0785\n",
      "Lr:     0.0010 Lambda:    10.0000 Epochs: 2000 Train Accuracy:     0.0794 Validation Accuracy:     0.0785\n",
      "Lr:     0.0010 Lambda:   100.0000 Epochs: 2000 Train Accuracy:     0.0794 Validation Accuracy:     0.0786\n",
      "Lr:     0.0010 Lambda:  1000.0000 Epochs: 2000 Train Accuracy:     0.0794 Validation Accuracy:     0.0793\n",
      "Lr:     0.0050 Lambda:     0.0010 Epochs: 2000 Train Accuracy:     0.0976 Validation Accuracy:     0.0948\n",
      "Lr:     0.0050 Lambda:     0.0100 Epochs: 2000 Train Accuracy:     0.0976 Validation Accuracy:     0.0948\n",
      "Lr:     0.0050 Lambda:     0.1000 Epochs: 2000 Train Accuracy:     0.0976 Validation Accuracy:     0.0948\n",
      "Lr:     0.0050 Lambda:     1.0000 Epochs: 2000 Train Accuracy:     0.0976 Validation Accuracy:     0.0948\n",
      "Lr:     0.0050 Lambda:    10.0000 Epochs: 2000 Train Accuracy:     0.0976 Validation Accuracy:     0.0948\n",
      "Lr:     0.0050 Lambda:   100.0000 Epochs: 2000 Train Accuracy:     0.0979 Validation Accuracy:     0.0952\n",
      "Lr:     0.0050 Lambda:  1000.0000 Epochs: 2000 Train Accuracy:     0.1021 Validation Accuracy:     0.0987\n",
      "Lr:     0.0100 Lambda:     0.0010 Epochs: 2000 Train Accuracy:     0.1155 Validation Accuracy:     0.1107\n",
      "Lr:     0.0100 Lambda:     0.0100 Epochs: 2000 Train Accuracy:     0.1155 Validation Accuracy:     0.1107\n",
      "Lr:     0.0100 Lambda:     0.1000 Epochs: 2000 Train Accuracy:     0.1155 Validation Accuracy:     0.1107\n",
      "Lr:     0.0100 Lambda:     1.0000 Epochs: 2000 Train Accuracy:     0.1155 Validation Accuracy:     0.1107\n",
      "Lr:     0.0100 Lambda:    10.0000 Epochs: 2000 Train Accuracy:     0.1158 Validation Accuracy:     0.1108\n",
      "Lr:     0.0100 Lambda:   100.0000 Epochs: 2000 Train Accuracy:     0.1167 Validation Accuracy:     0.1112\n",
      "Lr:     0.0100 Lambda:  1000.0000 Epochs: 2000 Train Accuracy:     0.1270 Validation Accuracy:     0.1202\n",
      "Lr:     0.0500 Lambda:     0.0010 Epochs: 2000 Train Accuracy:     0.1691 Validation Accuracy:     0.1523\n",
      "Lr:     0.0500 Lambda:     0.0100 Epochs: 2000 Train Accuracy:     0.1691 Validation Accuracy:     0.1523\n",
      "Lr:     0.0500 Lambda:     0.1000 Epochs: 2000 Train Accuracy:     0.1691 Validation Accuracy:     0.1523\n",
      "Lr:     0.0500 Lambda:     1.0000 Epochs: 2000 Train Accuracy:     0.1692 Validation Accuracy:     0.1526\n",
      "Lr:     0.0500 Lambda:    10.0000 Epochs: 2000 Train Accuracy:     0.1697 Validation Accuracy:     0.1530\n",
      "Lr:     0.0500 Lambda:   100.0000 Epochs: 2000 Train Accuracy:     0.1774 Validation Accuracy:     0.1575\n",
      "Lr:     0.0500 Lambda:  1000.0000 Epochs: 2000 Train Accuracy:     0.2212 Validation Accuracy:     0.1901\n",
      "Lr:     0.1000 Lambda:     0.0010 Epochs: 2000 Train Accuracy:     0.1984 Validation Accuracy:     0.1646\n",
      "Lr:     0.1000 Lambda:     0.0100 Epochs: 2000 Train Accuracy:     0.1984 Validation Accuracy:     0.1646\n",
      "Lr:     0.1000 Lambda:     0.1000 Epochs: 2000 Train Accuracy:     0.1984 Validation Accuracy:     0.1646\n",
      "Lr:     0.1000 Lambda:     1.0000 Epochs: 2000 Train Accuracy:     0.1986 Validation Accuracy:     0.1644\n",
      "Lr:     0.1000 Lambda:    10.0000 Epochs: 2000 Train Accuracy:     0.2004 Validation Accuracy:     0.1661\n",
      "Lr:     0.1000 Lambda:   100.0000 Epochs: 2000 Train Accuracy:     0.2160 Validation Accuracy:     0.1803\n",
      "Lr:     0.1000 Lambda:  1000.0000 Epochs: 2000 Train Accuracy:     0.2261 Validation Accuracy:     0.1935\n"
     ]
    }
   ],
   "source": [
    "epochs = 2000\n",
    "for lr in  [0.001, 0.005, 0.01, 0.05, 0.1]:\n",
    "    for lamb in [0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]:\n",
    "        #print(\"Training Accuracy \\n\")\n",
    "        w, b, losses =  fit_reg_lamb(X_train, train_y, lr=lr, epochs=epochs, lamb=lamb)\n",
    "        train_accuracy, train_confusion_matrix, train_sum_preds, train_sum_correct, train_misclassification_error = model_predict_accuracy(X_train, train_y, w, b)\n",
    "        val_accuracy, val_confusion_matrix, val_sum_preds, val_sum_correct, val_misclassification_error = model_predict_accuracy(X_val, val_y, w, b)\n",
    "        print(f'Lr: {lr:10.4f} Lambda: {lamb: 10.4f} Epochs: {epochs} Train Accuracy: {train_accuracy: 10.4f} Validation Accuracy: {val_accuracy: 10.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "715fddbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lr:     0.1000 Lambda:   100.0000 Epochs: 5000 Train Accuracy:     0.2613 Validation Accuracy:     0.2095\n",
      "Lr:     0.1000 Lambda:  1000.0000 Epochs: 5000 Train Accuracy:     0.2258 Validation Accuracy:     0.1927\n",
      "Lr:     0.1000 Lambda:   100.0000 Epochs: 8000 Train Accuracy:     0.2730 Validation Accuracy:     0.2175\n",
      "Lr:     0.1000 Lambda:  1000.0000 Epochs: 8000 Train Accuracy:     0.2258 Validation Accuracy:     0.1927\n",
      "Lr:     0.1000 Lambda:   100.0000 Epochs: 12000 Train Accuracy:     0.2759 Validation Accuracy:     0.2173\n",
      "Lr:     0.1000 Lambda:  1000.0000 Epochs: 12000 Train Accuracy:     0.2258 Validation Accuracy:     0.1927\n"
     ]
    }
   ],
   "source": [
    "lr = 0.10 \n",
    "for epochs in [5000, 8000, 12000]:\n",
    "    for lamb in [100.0, 1000.0]:\n",
    "        #print(\"Training Accuracy \\n\")\n",
    "        w, b, losses =  fit_reg_lamb(X_train, train_y, lr=lr, epochs=epochs, lamb=lamb)\n",
    "        train_accuracy, train_confusion_matrix, train_sum_preds, train_sum_correct, train_misclassification_error = model_predict_accuracy(X_train, train_y, w, b)\n",
    "        val_accuracy, val_confusion_matrix, val_sum_preds, val_sum_correct, val_misclassification_error = model_predict_accuracy(X_val, val_y, w, b)\n",
    "        print(f'Lr: {lr:10.4f} Lambda: {lamb: 10.4f} Epochs: {epochs} Train Accuracy: {train_accuracy: 10.4f} Validation Accuracy: {val_accuracy: 10.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af92109c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5ec558",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2489931",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb19006",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
